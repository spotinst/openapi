type: object
required:
- internalId
- id
- displayName
- accountId
- organizationId
- userId
- clusterId
- controllerClusterId
- appState
- submissionSource
- createdAt
- updatedAt
allOf:
- $ref: "../../../../commons/schemas/createdAtUpdatedAt.yaml"
- type: object
  description: >
    The description of a Spark application
  properties:
    internalId:
      $ref: "internalId.yaml"
    id:
      $ref: "oceanSparkApplicationId.yaml"
    displayName:
      $ref: "oceanSparkApplicationDisplayName.yaml"
    userId:
      $ref: "userId.yaml"
    clusterId:
      $ref: "oceanSparkClusterId.yaml"
    controllerClusterId:
      $ref: "controllerClusterId.yaml"
    appState:
      $ref: "oceanSparkApplicationState.yaml"
    submissionSource:
      $ref: "oceanSparkApplicationSubmissionSource.yaml"
    job:
      type: object
      description: >
        The job to which the application belongs.
        A job is collection of Spark applications, typically a workload run on a schedule.
      required:
        - id
        - displayName
      properties:
        id:
          $ref: oceanSparkJobId.yaml
        displayName:
          $ref: oceanSparkJobDisplayName.yaml
    config:
      $ref: "oceanSparkApplicationSpec.yaml"
    startedAt:
      type: string
      format: date-time
      description: >
        The time when the Spark application started running (the app state becomes RUNNING).
        This is not the time when the application launch was requested (this is `createdAt`).
      example: "2021-11-18T17:09:37+00:00"
    endedAt:
      type: string
      format: date-time
      description: >
        The time when the Spark application terminated.
      example: "2021-11-18T17:09:37+00:00"
    log:
      type: object
      description: API pointers to endpoints serving logs and events related to the Spark application
      properties:
        logsStreamUrl:
          type: string
          format: uri
          description: URL of the endpoint serving the live driver logs
          example: /ocean/spark/cluster/osc-20fac3f1/app/daily-reporting-2021-08-18/logs/live
        kubeEventsStreamUrl:
          type: string
          format: uri
          description: URL of the endpoint serving a stream of Kubernetes events
          example: /ocean/spark/cluster/osc-20fac3f1/app/daily-reporting-2021-08-18/kubeEvents/live
    metrics:
      type: object
      description: Metrics about the Spark application
      properties:
        cost:
          type: object
          required:
          - nonPvStorage
          - storage
          - compute
          - total
          - createdAt
          - updatedAt
          description: The cloud cost of the Spark application. Updated every hour
          properties:
            createdAt:
              # I had to write createdAt and updatedAt manually and not use createdAtUpdatedAt.yaml.
              # Otherwise the object is marked as "recursive". This looks like a redoc bug.
              $ref: "createdAt.yaml"
            updatedAt:
              $ref: "updatedAt.yaml"
            nonPvStorage:
              type: integer
              description: The portion of the cost associated to ephemeral storage in USD cents
              example: 0
            storage:
              type: integer
              description: The portion of the cost associated to persistent storage in USD cents
              example: 0
            compute:
              type: integer
              description: The portion of the cost associated to compute in USD cents
              example: 0
            total:
              type: integer
              description: The total cost of the Spark application in USD cents
              example: 0
        spark:
          type: object
          description: Computed statistics about the performance of the Spark application
          required:
          - inputDataBytes
          - outputDataBytes
          - sparkCoresDurationSeconds
          - efficiencyPercent
          - createdAt
          - updatedAt
          properties:
            createdAt:
              # I had to write createdAt and updatedAt manually and not use a $ref.
              # Otherwise the object is marked as "recursive". This looks like a redoc bug.
              $ref: "createdAt.yaml"
            updatedAt:
              $ref: "updatedAt.yaml"
            sparkCoresDurationSeconds:
              format: time-delta
              type: number
              description: >
                The total core ressources used by the application.
                This metric is calculated as the sum over each container (driver or executor)
                of its uptime duration multiplied by the number of cores allocated to it.
            inputDataBytes:
              type: integer
              description: >
                The number of bytes read by Spark, typically from an object store.
            outputDataBytes:
              type: integer
              description: >
                The number of bytes written by Spark, typically to an object store.
            durationSeconds:
              description: >
                The duration of the Spark application
              format: time-delta
              type: number
            efficiencyPercent:
              type: number
              description: >
                The fraction of the time that Spark executor cores are running Spark tasks.
